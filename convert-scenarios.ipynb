{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import ukpopulation.utils as ukpoputils\n",
    "import ukpopulation.snhpdata as SNHPData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('.', 'data_as_provided')\n",
    "output_path = os.path.join('.', 'data_processed')\n",
    "\n",
    "keys = ['baseline', '0-unplanned', '1-new-cities', '2-expansion', '3-new-cities23', '4-expansion23', '5-new-cities23-nb', '6-new-cities30-nb']\n",
    "\n",
    "filenames = {\n",
    "    'baseline': os.path.join(data_path, 'Scenario Baseline - Dwelling+Employment projections.xlsx'), \n",
    "    '0-unplanned': os.path.join(data_path, 'Scenario Unplanned Development - Dwelling+Employment projections.xlsx'), \n",
    "    '1-new-cities': os.path.join(data_path, 'Scenario New Settlements - Dwelling+Employment projections.xlsx'), \n",
    "    '2-expansion': os.path.join(data_path, 'Scenario Expansion - Dwelling+Employment projections.xlsx'), \n",
    "    '3-new-cities23': os.path.join(data_path, 'Scenario New Settlements 23000.xlsx'), \n",
    "    '4-expansion23': os.path.join(data_path, 'Scenario Expansion 23000.xlsx'),\n",
    "    '5-new-cities23-nb': os.path.join(data_path, 'Scenario New Settlements 23000_no_base_change.xlsx'),\n",
    "    '6-new-cities30-nb': os.path.join(data_path, 'Scenario New Settlements 30000_no_base_change.xlsx'),\n",
    "}\n",
    "\n",
    "sheets = {\n",
    "    'baseline': 'Projection dwelling baseline',\n",
    "    '0-unplanned':  'Projection UnplannedDev',\n",
    "    '1-new-cities': 'Projection New Settlem data',\n",
    "    '2-expansion': 'Projection Expansion data',\n",
    "    '3-new-cities23': 'Projection New Settlem data',\n",
    "    '4-expansion23': 'Projection Expansion data',\n",
    "    '5-new-cities23-nb': 'Projection New Settlem data',\n",
    "    '6-new-cities30-nb': 'Projection New Settlem data',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_households(year, geogs, df): \n",
    "    \"\"\"Use UKPopulation to obtain historical and extrapolated household data for all other LADs\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    year : int\n",
    "    geogs : list\n",
    "    df : pandas.DataFrame\n",
    "        The raw data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    geogs = ukpoputils.split_by_country(geogs)\n",
    "\n",
    "    allsnhp = pd.DataFrame()\n",
    "\n",
    "    for country in geogs:\n",
    "        if not geogs[country]: continue\n",
    "        max_year = df.max_year(country)\n",
    "        min_year = df.min_year(country)\n",
    "\n",
    "        if year <= max_year:\n",
    "            if year <= min_year:\n",
    "                snhp = df.aggregate(geogs[country], min_year+1).merge(\n",
    "                            df.aggregate(geogs[country], min_year), \n",
    "                            left_on=\"GEOGRAPHY_CODE\", right_on=\"GEOGRAPHY_CODE\")\n",
    "                snhp[\"HOUSEHOLDS\"] = snhp.OBS_VALUE_y + (snhp.OBS_VALUE_y - snhp.OBS_VALUE_x) * (min_year - year)\n",
    "                snhp[\"PROJECTED_YEAR_NAME\"] = year\n",
    "                snhp.drop([\"PROJECTED_YEAR_NAME_x\", \"OBS_VALUE_x\", \"PROJECTED_YEAR_NAME_y\", \"OBS_VALUE_y\"], axis=1, inplace=True)\n",
    "            else:\n",
    "                snhp = df.aggregate(geogs[country], year).rename({\"OBS_VALUE\": \"HOUSEHOLDS\"}, axis=1)\n",
    "        else:\n",
    "            snhp = df.aggregate(\n",
    "                geogs[country], max_year-1).merge(\n",
    "                df.aggregate(geogs[country], max_year), \n",
    "                left_on=\"GEOGRAPHY_CODE\", right_on=\"GEOGRAPHY_CODE\")\n",
    "            snhp[\"HOUSEHOLDS\"] = snhp.OBS_VALUE_y + (snhp.OBS_VALUE_y - snhp.OBS_VALUE_x) * (year - max_year)\n",
    "            snhp[\"PROJECTED_YEAR_NAME\"] = year\n",
    "            snhp.drop([\"PROJECTED_YEAR_NAME_x\", \"OBS_VALUE_x\", \"PROJECTED_YEAR_NAME_y\", \"OBS_VALUE_y\"], axis=1, inplace=True)\n",
    "\n",
    "        allsnhp = allsnhp.append(snhp, ignore_index=True, sort=False)\n",
    "\n",
    "    return allsnhp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    df = df.dropna(\n",
    "        ).reset_index(\n",
    "        ).melt(\n",
    "            id_vars='Area Name',\n",
    "            var_name='timestep',\n",
    "            value_name='dwellings')\n",
    "    df = df.set_index(['Area Name', 'timestep'])\n",
    "    return df\n",
    "\n",
    "lad_nmcds = pd.read_csv(os.path.join(data_path, 'lad_nmcd_changes.csv'))\n",
    "lad_nmcds = lad_nmcds[['lad16nm', 'lad16cd']]\n",
    "all_lad_nms = set(lad_nmcds.lad16nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_national_data(df, lad_nmcds, snhp):\n",
    "    all_lads = set(lad_nmcds['lad16cd'])\n",
    "    arc_lads = set(df.reset_index()['lad16cd'].unique())\n",
    "    required_lads = all_lads - arc_lads\n",
    "\n",
    "    years = list(df['timestep'].unique())\n",
    "    dfs = [df]\n",
    "    for year in years:\n",
    "        national_data = get_households(year, required_lads, snhp)\n",
    "        national_data = national_data.rename(columns={'GEOGRAPHY_CODE': 'lad16cd',\n",
    "                                      'PROJECTED_YEAR_NAME': 'timestep',\n",
    "                                      'HOUSEHOLDS': 'dwellings'})\n",
    "        dfs.append(national_data)\n",
    "    df = pd.concat(dfs, sort=False)\n",
    "    df = df.rename(columns={'lad16cd': 'lad_uk_2016'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lad_codes(df):\n",
    "\n",
    "    baseline_lad_nms = set(df.reset_index()['Area Name'].unique())\n",
    "    df_wlad = df.reset_index().merge(lad_nmcds, \n",
    "                                     left_on='Area Name', \n",
    "                                     right_on='lad16nm').drop(columns='Area Name')\n",
    "    return df_wlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out(df, filename):\n",
    "    df.to_csv(os.path.join(output_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snhp = SNHPData.SNHPData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_into_df(filename, sheet_name):\n",
    "    \n",
    "    years = [str(x) for x in range(2004, 2050)]\n",
    "    types = {str(year): int for year in years}\n",
    "    \n",
    "    return pd.read_excel(\n",
    "        filename, \n",
    "        sheet_name=sheet_name, \n",
    "        header=3, \n",
    "        index_col=0,\n",
    "        names=['Area Name'].extend(years),\n",
    "        nrows=26,  # magic number of rows\n",
    "        dtype=types\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for scenario in keys:\n",
    "    df = read_excel_into_df(filenames[scenario], sheets[scenario])\n",
    "    df = process_df(df)\n",
    "    df = add_lad_codes(df)\n",
    "    data[scenario] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_lads = set(data['baseline'].reset_index()['lad16nm'].unique())\n",
    "assert len(arc_lads) == 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in keys:\n",
    "    assert len(data[scenario][data[scenario].timestep.isin([2015,2050])]) == len(arc_lads)*2, scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_national = {}\n",
    "for key, df in data.items():\n",
    "    df = add_national_data(df, lad_nmcds, snhp)\n",
    "    data_national[key] = df\n",
    "    write_out(df, 'arc_dwellings__{}.csv'.format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_arc(df, lad_nmcds, arc_lads):   \n",
    "    just_arc_lads = df.lad_uk_2016.isin(lad_nmcds[lad_nmcds.lad16nm.isin(arc_lads)].lad16cd)\n",
    "    \n",
    "    df = df[just_arc_lads]\n",
    "    df = df.set_index(['timestep', 'lad_uk_2016'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas = filter_on_arc(data_national['baseline'], lad_nmcds, arc_lads)\n",
    "bas['unplanned'] = filter_on_arc(data_national['0-unplanned'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas['settlements'] = filter_on_arc(data_national['1-new-cities'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas['expansion'] = filter_on_arc(data_national['2-expansion'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas['settlements23'] = filter_on_arc(data_national['3-new-cities23'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas['expansion23'] = filter_on_arc(data_national['4-expansion23'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas['settlements23nb'] = filter_on_arc(data_national['5-new-cities23-nb'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas['settlements30nb'] = filter_on_arc(data_national['6-new-cities30-nb'], lad_nmcds, arc_lads)['dwellings']\n",
    "bas = bas.rename(columns={'dwellings': 'baseline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bas[['expansion', 'expansion23', 'unplanned', 'baseline']]\n",
    "df.groupby(by='timestep').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bas[['settlements', 'settlements23']]\n",
    "df.groupby(by='timestep').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bas[['settlements30nb', 'settlements23nb']]\n",
    "df.groupby(by='timestep').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Number of LADs in data: {}\".format(len(data_national['baseline'].lad_uk_2016.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = data_national['baseline']\n",
    "unplanned = data_national['0-unplanned']\n",
    "settlements = data_national['1-new-cities']\n",
    "expansion = data_national['2-expansion']\n",
    "settlements23 = data_national['3-new-cities23']\n",
    "expansion23 = data_national['4-expansion23']\n",
    "settlements23nb = data_national['5-new-cities23-nb']\n",
    "settlements30nb = data_national['6-new-cities30-nb']\n",
    "\n",
    "baseline['scenario'] = 'baseline'\n",
    "expansion['scenario'] = 'expansion'\n",
    "settlements['scenario'] = 'settlements'\n",
    "unplanned['scenario'] = 'unplanned'\n",
    "settlements23['scenario'] = 'settlements23'\n",
    "expansion23['scenario'] = 'expansion23'\n",
    "settlements23nb['scenario'] = 'settlements23-nb'\n",
    "settlements30nb['scenario'] = 'settlements-nb'\n",
    "df = pd.concat([baseline, expansion, settlements, unplanned, expansion23, settlements23, settlements23nb, settlements30nb])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = df.groupby(\n",
    "    ['timestep','scenario']\n",
    ").sum().reset_index().pivot(\n",
    "    index='timestep', columns='scenario', values='dwellings'\n",
    ")\n",
    "pivoted.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pd.pivot_table(\n",
    "    df, index=['timestep', 'lad_uk_2016'], columns='scenario', values='dwellings'\n",
    ").reset_index().set_index('timestep')\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted[pivoted.lad_uk_2016 =='E07000178'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
